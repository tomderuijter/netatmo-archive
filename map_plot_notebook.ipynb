{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n",
    "This notebook will display the spatial patterns of pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from domain.base import Station\n",
    "import domain.mongodb_engine as mongodb\n",
    "\n",
    "from helpers.utils import (\n",
    "    get_station_coordinates,\n",
    "    select_near,\n",
    "    add_alias\n",
    ")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's load up data from the MongoDB running in the back.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from database\n",
    "module_list = {\n",
    "    'thermo_module': [\n",
    "        'temperature',\n",
    "        'pressure'\n",
    "    ],\n",
    "}\n",
    "\n",
    "db_connector = mongodb.MongoDBConnector()\n",
    "stations = list(db_connector.db.stations.find())\n",
    "stations = [Station.from_dict(s) for s in stations]\n",
    "print(\"Found %d stations in area.\" % len(stations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to convert each station's data to dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def convert_module(station, attribute):\n",
    "    module = getattr(station, attribute)\n",
    "    df = pd.DataFrame(module).sort_values('valid_datetime')\\\n",
    "        .drop_duplicates().set_index('valid_datetime', drop=True)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df.resample('10T').mean().interpolate(method='time', limit=2)\n",
    "    setattr(station, attribute, df)\n",
    "    return station\n",
    "    \n",
    "    \n",
    "def valid_module(station, attribute):\n",
    "    return hasattr(station, attribute) and getattr(station, attribute) is not None\n",
    "\n",
    "\n",
    "def create_dataframe_of_attribute(data, attribute):\n",
    "    assert isinstance(data, list)\n",
    "\n",
    "    data = Parallel(n_jobs=8)(\n",
    "        delayed(convert_module)(station, attribute) \n",
    "        for station in data \n",
    "        if valid_module(station, attribute)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "stations = create_dataframe_of_attribute(stations, 'thermo_module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do large scale analysis and plotting, we need to convert all the separate station dataframes into a single large dataframe. We will do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe_of_stations(stations, module):\n",
    "    return pd.concat(\n",
    "        [\n",
    "            getattr(station, module).add_suffix('_' + str(station_id)) \n",
    "            for station_id, station in enumerate(stations)\n",
    "            if valid_module(station, module)\n",
    "        ], \n",
    "        axis=1, join='outer',\n",
    "    )\n",
    "\n",
    "data = create_dataframe_of_stations(stations, 'thermo_module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's plot a few time series.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_id = 101\n",
    "\n",
    "# Temperature time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "data['pressure_' + str(station_id)].plot()\n",
    "plt.title(\"Station {}\".format(station_id))\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Temperature derivative\n",
    "old_columns = [c for c in data.columns.values if c.startswith('temperature')]\n",
    "new_columns = ['temperature-gradient_' + c.split('_')[1] for c in old_columns]\n",
    "gradients = data[old_columns].diff().rolling(window=6).mean().rename(columns=dict(zip(old_columns, new_columns)))\n",
    "data = pd.concat([data, gradients], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is displaying variables on a map.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_map(data, stations, element, index):\n",
    "    assert isinstance(data, pd.DataFrame)\n",
    "    \n",
    "    columns = [c for c in data.columns.values if c.startswith(element + '_')]\n",
    "    vals = data.loc[index, columns]\n",
    "    lats = [s.latitude for s in stations]\n",
    "    lons = [s.longitude for s in stations]\n",
    "    \n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    plt.title(element + ' - ' + str(index))\n",
    "    if element == 'pressure':\n",
    "        make_pressure_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'temperature':\n",
    "        make_temperature_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'temperature-gradient':\n",
    "        make_gradient_map(plt.gca(), lats, lons, vals)\n",
    "    return f\n",
    "\n",
    "\n",
    "def make_gradient_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, -.15, .15)\n",
    "    \n",
    "def make_temperature_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, 0, 15)\n",
    "    \n",
    "def make_pressure_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, 950, 1050)\n",
    "\n",
    "def scatter(ax, lats, lons, vals, vmin=None, vmax=None):\n",
    "    sc = ax.scatter(\n",
    "        lons, lats,\n",
    "        c=vals,\n",
    "        linewidths=0,\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    plt.colorbar(sc)\n",
    "    \n",
    "index = '2016-12-14 23:40'\n",
    "element = 'temperature'\n",
    "f = make_map(data, stations, element, index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, create a series of maps for using in a moving picture.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def date_range(start_date, end_date, minute_increment=30):\n",
    "    d = start_date\n",
    "    while d <= end_date:\n",
    "        yield d\n",
    "        d += timedelta(minutes=minute_increment)\n",
    "\n",
    "\n",
    "start_date = data.index[0]\n",
    "end_date = data.index[-1]\n",
    "element = 'temperature'\n",
    "\n",
    "for index in date_range(start_date, end_date, 10):\n",
    "    f = make_map(data, stations, element, index)\n",
    "    fig_name = 'img/gif_images/' + element + '/' + element + '_' + str(index) + '.png'\n",
    "    f.savefig(fig_name)\n",
    "    plt.close(f)\n",
    "    print(fig_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
