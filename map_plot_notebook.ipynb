{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n",
    "This notebook will display the spatial patterns of pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from domain.base import Station\n",
    "from domain.merge import merge_documents\n",
    "import domain.mongodb_engine as mongodb\n",
    "\n",
    "from helpers.utils import (\n",
    "    get_station_coordinates,\n",
    "    select_near,\n",
    "    add_alias\n",
    ")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's load up data from the MongoDB running in the back.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15186 stations in area.\n"
     ]
    }
   ],
   "source": [
    "# Load data from database\n",
    "db_connector = mongodb.MongoDBConnector()\n",
    "stations = list(db_connector.db.stations.find())\n",
    "stations = [Station.from_dict(s) for s in stations]\n",
    "stations = merge_documents(stations)\n",
    "print(\"Found %d stations in area.\" % len(stations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(stations, open('data_netatmo.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to convert each station's data to dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def convert_module(station, attribute):\n",
    "    module = getattr(station, attribute)\n",
    "    \n",
    "    if attribute == 'hydro_module':\n",
    "        index_name = 'time_hour_rain'\n",
    "    else:\n",
    "        index_name = 'valid_datetime'\n",
    "    \n",
    "    df = pd.DataFrame(module).sort_values(index_name)\\\n",
    "        .drop_duplicates().set_index(index_name, drop=True)\n",
    "            \n",
    "    if not df.empty:\n",
    "        df = df.resample('10T').mean().interpolate(method='time', limit=2)\n",
    "    setattr(station, attribute, df)\n",
    "    return station\n",
    "    \n",
    "    \n",
    "def valid_module(station, attribute):\n",
    "    return hasattr(station, attribute) and getattr(station, attribute) is not None\n",
    "\n",
    "\n",
    "def create_dataframe_of_attribute(data, attribute):\n",
    "    assert isinstance(data, list)\n",
    "\n",
    "    data = Parallel(n_jobs=8)(\n",
    "        delayed(convert_module)(station, attribute) \n",
    "        for station in data \n",
    "        if valid_module(station, attribute)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "stations = create_dataframe_of_attribute(stations, 'hydro_module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do large scale analysis and plotting, we need to convert all the separate station dataframes into a single large dataframe. We will do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe_of_stations(stations, module):\n",
    "    return pd.concat(\n",
    "        [\n",
    "            getattr(station, module).add_suffix('_' + str(station_id)) \n",
    "            for station_id, station in enumerate(stations)\n",
    "            if valid_module(station, module)\n",
    "        ], \n",
    "        axis=1, join='outer',\n",
    "    )\n",
    "\n",
    "data = create_dataframe_of_stations(stations, 'hydro_module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's plot a few time series.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Temperature derivative\n",
    "old_columns = [c for c in data.columns.values if c.startswith('temperature_')]\n",
    "new_columns = ['temperature-gradient_' + c.split('_')[1] for c in old_columns]\n",
    "gradients = data[old_columns].diff().rolling(window=6).mean().rename(columns=dict(zip(old_columns, new_columns)))\n",
    "data = pd.concat([data, gradients], axis=1, join='inner')\n",
    "\n",
    "# Pressure gradient\n",
    "old_columns = [c for c in data.columns.values if c.startswith('pressure_')]\n",
    "new_columns = ['pressure-gradient_' + c.split('_')[1] for c in old_columns]\n",
    "gradients = data[old_columns].diff().rolling(window=6).mean().rename(columns=dict(zip(old_columns, new_columns)))\n",
    "data = pd.concat([data, gradients], axis=1, join='inner')\n",
    "\n",
    "old_columns = [c for c in data.columns.values if c.startswith('pressure_')]\n",
    "new_columns = ['pressure-second-moment_' + c.split('_')[1] for c in old_columns]\n",
    "gradients = data[old_columns].diff().rolling(window=6).mean().diff().rolling(window=6).mean().rename(columns=dict(zip(old_columns, new_columns)))\n",
    "data = pd.concat([data, gradients], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_id = 101\n",
    "\n",
    "# Temperature time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "data['pressure-second-moment_' + str(station_id)].plot()\n",
    "plt.title(\"Station {}\".format(station_id))\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is displaying variables on a map.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pressure_gradients = [c for c in data.columns.values if c.startswith('pressure-second-moment')]\n",
    "all_gradients = data[pressure_gradients].values[:]\n",
    "all_gradients = all_gradients[~np.isnan(all_gradients)]\n",
    "plt.hist(all_gradients, bins=np.arange(-.2, .2, 0.01))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def make_map(data, stations, element, index):\n",
    "    assert isinstance(data, pd.DataFrame)\n",
    "    \n",
    "    columns = [c for c in data.columns.values if c.startswith(element + '_')]\n",
    "    vals = data.loc[index, columns]\n",
    "    lats = [s.latitude for s in stations]\n",
    "    lons = [s.longitude for s in stations]\n",
    "    \n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    plt.title(element + ' - ' + str(index))\n",
    "    if element == 'pressure':\n",
    "        make_pressure_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'temperature':\n",
    "        make_temperature_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'temperature-gradient':\n",
    "        make_gradient_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'pressure-gradient':\n",
    "        make_pressure_gradient_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'pressure-second-moment':\n",
    "        make_pressure_second_moment_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'daily_rain_sum':\n",
    "        make_daily_precipitation_map(plt.gca(), lats, lons, vals)\n",
    "    elif element == 'hourly_rain_sum':\n",
    "        make_hourly_precipitation_map(plt.gca(), lats, lons, vals)\n",
    "    else:\n",
    "        scatter(plt.gca(), lats, lons, vals)\n",
    "    return f\n",
    "\n",
    "\n",
    "def make_gradient_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, -.15, .15)\n",
    "    \n",
    "def make_temperature_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, 0, 15)\n",
    "    \n",
    "def make_pressure_map(ax, lats, lons, vals):\n",
    "    mean = np.mean(vals)\n",
    "    var = np.var(vals)\n",
    "    scatter(ax, lats, lons, vals, mean-var, mean+var)\n",
    "\n",
    "def make_pressure_gradient_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, -.5, .5)\n",
    "    \n",
    "def make_pressure_second_moment_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, -.03, .03)\n",
    "    \n",
    "def make_daily_precipitation_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, 0, .5)\n",
    "    \n",
    "def make_hourly_precipitation_map(ax, lats, lons, vals):\n",
    "    scatter(ax, lats, lons, vals, 0, .1)\n",
    "\n",
    "def scatter(ax, lats, lons, vals, vmin=None, vmax=None):\n",
    "    sc = ax.scatter(\n",
    "        lons, lats,\n",
    "        c=vals,\n",
    "        linewidths=0,\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    plt.colorbar(sc)\n",
    "    \n",
    "index = '2017-03-13 20:00'\n",
    "element = 'hourly_rain_sum'\n",
    "f = make_map(data, stations, element, index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, create a series of maps for using in a moving picture.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def date_range(start_date, end_date, minute_increment=30):\n",
    "    d = start_date\n",
    "    while d <= end_date:\n",
    "        yield d\n",
    "        d += timedelta(minutes=minute_increment)\n",
    "\n",
    "\n",
    "start_date = data.index[0]\n",
    "end_date = data.index[-1]\n",
    "element = 'pressure-second-moment'\n",
    "\n",
    "for index in date_range(start_date, end_date, 10):\n",
    "    f = make_map(data, stations, element, index)\n",
    "    fig_name = 'img/gif_images/' + element + '/' + element + '_' + str(index) + '.png'\n",
    "    f.savefig(fig_name)\n",
    "    plt.close(f)\n",
    "    print(fig_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
